{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Visualizations and Data Cleaning\n",
    "\n",
    "## 3/8/22\n",
    "\n",
    "### Table of Contents\n",
    "1. [Types of Variables](#typesofvariables)\n",
    "2. [Matplotlib vs. Seaborn](#pltvssns)\n",
    "4. [Data Loading](#data-loading)  \n",
    "5. [Exploratory Data Analysis (EDA)](#eda)\n",
    "6. [Data Cleaning and Feature Engineering](#feature-engineering)\n",
    "7. [References/Resources](#ref)\n",
    "\n",
    "### Hosted by and maintained by the [Student Association for Applied Statistics (SAAS)](https://saas.berkeley.edu/).\n",
    "\n",
    "### Presented by Jade Pan, Jonathan Pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "# Setup code\n",
    "import seaborn as sns #; sns.set()\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%matplotlib inline` makes it so that all the plots will be shown underneath the code, otherwise we'd have to type `plt.show()` after each plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='typesofvariables'></a>\n",
    "# Types of Variables\n",
    "\n",
    "Understanding what types of data you're working with—and hence what types of variables your data has—is essential when determining what kinds of visualizations may be most appropriate and most effective to illustrate your data. Not all visualizations are suited for all types of data! It is also important to understand the types of variables in your dataset when considering what specific goal(s) you want to accomplish with your visualizations; this concept will become more clear as we continue through this lecture notebook.\n",
    "\n",
    "There are two principal categories of data, each of which can be subdivided into two subcategories; this gives us four main categories of data in total:\n",
    "\n",
    "- **Qualitative/Categorical**: a variable that has discrete values or distinct characteristics that represent *categories*\n",
    "    - **Ordinal**: a categorical variable whose categories have a clear *ordering* or sequence, so the categories have a numerical or sequential meaning. \n",
    "        - e.g. education level: `elementary school`, `middle school`, `high school`; year in Berkeley: `freshman`, `sophomore`, `junior`, `senior`\n",
    "    - **Nominal**: a categorial variable whose categories exist by *name* only, with no inherent numerical value or sequential ordering\n",
    "        - e.g. `Cal ID number`; major at UC Berkeley: `data science`, `statistics`, `computer science`, `economics`\n",
    "- **Quantitative/Numerical**: a variable that is measured on a numeric scale\n",
    "    - **Continuous**: a quantitative variable that can take on an infinite number of values; think of continuous quantitative variables as things you can measure.\n",
    "        - e.g. `weight`, `temperature`\n",
    "    - **Discrete**: a quantitative variable that can only take on certain values, usually integer values; think of discrete quantitative variables as things you can count.\n",
    "        - e.g. `number of siblings`, `number of semesters completed at UC Berkeley`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pltvssns'></a>\n",
    "# Matplotlib vs Seaborn\n",
    "\n",
    "- [Matplotlib](https://www.kdnuggets.com/2019/04/data-visualization-python-matplotlib-seaborn.html ) is a Python data visualization library built on NumPy arrays\n",
    "- [Official Seaborn tutorial](https://seaborn.pydata.org/tutorial.html)\n",
    "- Seaborn is based off the Matplotlib library, but is used to create more aesthetic and informative graphics\n",
    "- Matplotlib mostly plots basic fundamental visualizations, whereas seaborn has the capacity to plot more advanced visualizations that can summarize data with distributions and densities \n",
    "- When it comes to more advanced data visualizations, seaborn creates more aesthetic graphs (e.g. often has built-in functionality for color-coding certain categorical variables)\n",
    "\n",
    "Throughout this notebook, we'll mainly be dealing with seaborn. In practice though, the choice is up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are exploring is collected from a bike sharing system in Washington D.C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset \n",
    "\n",
    "bike = pd.read_csv('bikeshare.txt')\n",
    "bike.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in this data frame are defined as:\n",
    "\n",
    "Variable       | Description\n",
    "-------------- | ------------------------------------------------------------------\n",
    "instant | record index\n",
    "dteday | date\n",
    "season | 1. spring <br> 2. summer <br> 3. fall <br> 4. winter\n",
    "yr | year (0: 2011, 1:2012)\n",
    "mnth | month ( 1 to 12)\n",
    "hr | hour (0 to 23)\n",
    "holiday | whether day is holiday or not\n",
    "weekday | day of the week\n",
    "workingday | if day is neither weekend nor holiday\n",
    "weathersit | 1. clear or partly cloudy <br> 2. mist and clouds <br> 3. light snow or rain <br> 4. heavy rain or snow\n",
    "temp | normalized temperature in Celsius (divided by 41)\n",
    "atemp | normalized \"feels-like\" temperature in Celsius (divided by 50)\n",
    "hum | normalized percent humidity (divided by 100)\n",
    "windspeed| normalized wind speed (divided by 67)\n",
    "casual | count of casual users\n",
    "registered | count of registered users\n",
    "cnt | count of total rental bikes including casual and registered \n",
    "\n",
    "Try to identify what type of variable each of the columns (except `instant`) in our dataset represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** What kind of variable would \"dteday\" be?\n",
    "\n",
    "a) Qualitative Ordinal\n",
    "\n",
    "b) Qualitative Nominal\n",
    "\n",
    "c) Quantitative Continuous \n",
    "\n",
    "d) Quantitative Discrete \n",
    "\n",
    "**Answer:** ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** What kind of variable would \"month\" be?\n",
    "\n",
    "a) Qualitative Ordinal\n",
    "\n",
    "b) Qualitative Nominal\n",
    "\n",
    "c) Quantitative Continuous \n",
    "\n",
    "d) Quantitative Discrete \n",
    "\n",
    "**Answer:** ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the dataset \n",
    "# don't worry about this code\n",
    "\n",
    "factor_dict = {\n",
    "    'holiday': {\n",
    "        0:'no', \n",
    "        1:'yes'\n",
    "    },\n",
    "    'weekday': {\n",
    "        0: 'Sun', \n",
    "        1: 'Mon', \n",
    "        2: 'Tue', \n",
    "        3: 'Wed', \n",
    "        4: 'Thu', \n",
    "        5: 'Fri', \n",
    "        6: 'Sat'\n",
    "    },\n",
    "    'workingday': {\n",
    "        0: 'no',\n",
    "        1: 'yes'\n",
    "    },\n",
    "    'weathersit': {\n",
    "        1: 'Clear',\n",
    "        2: 'Mist',\n",
    "        3: 'Light',\n",
    "        4: 'Heavy'\n",
    "    }\n",
    "}\n",
    "\n",
    "bike.replace(factor_dict, inplace=True)\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = (\n",
    "    bike\n",
    "    .groupby(['dteday'])\n",
    "    .agg(\n",
    "        {\n",
    "        \"casual\": sum, \n",
    "        \"registered\": sum, \n",
    "        \"workingday\": 'last'\n",
    "        }\n",
    "    )\n",
    ")\n",
    "daily_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='note'></a>\n",
    "## A Note on Plotting in Jupyter Notebooks\n",
    "\n",
    "You may have noticed that many of our code cells involving plotting end with a semicolon (;). This prevents any extra output from the last line of the cell that we may not want to see. Try adding this to your own code in the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lineplots'></a>\n",
    "## Lineplots\n",
    "\n",
    "One of the most fundamental types of plots is a lineplot. Lineplots are used to visualize relationships between **one numerical variable** on the y-axis and **one ordinal variable** on the x-axis. A lineplot consists of data points, often called *markers*, that are plotted on an *x,y* coordinate plane with straight lines connecting one point to the next. Often, lineplots are used to illustrate a trend in data values over a series of time, and hence the line follows chronological order from left to right; more specifically this plot would be called a *time series* plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pltlineplots'></a>\n",
    "### Lineplots in Matplotlib\n",
    "[Lineplots](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) are the simplest, most basic type of data visualization that you can plot in Matplotlib. They are created using the `plt.plot()` function, whose argument is just some data that we want to visualize! This data can be in the form of a NumPy array or a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see one way how `plt.plot()` works!\n",
    "plt.plot([1, 3, 2, 4, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, the list `[1, 3, 2, 4, 5]` that we passed into the `plt.plot()` function, because it is the only data argument, is assumed by Matplotlib to be a list of the y-values. Hence, it automatically assigns the integers `[0, 1, 2, 3, 4]` to be the x-values. When you plot values in this way, it will automatically assign x-values as a range from 0 up to the length of the y-values you passed in. \n",
    "\n",
    "If you want to define the x-values, you can just pass them in as the first argument, so you have the option of calling plot in either of the following ways:\n",
    "    \n",
    "    plt.plot(y_values)\n",
    "    plt.plot(x_values, y_values)\n",
    "    \n",
    "**Pro-tip:** After typing `plt.plot()` into a Jupyter Notebook code cell, you can use the `shift+tab` trick to see what arguments `plt.plot()` takes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see how we can pass in `x_values` and `y_values` into `plt.plot()`\n",
    "plt.plot([1, 4, 9, 16, 25], [1, 3, 2, 4, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Use the `bike_hr_avg_counts` dataframe below to plot the average number of **registered** bikeshare riders per hour of the day. Label your axes and add a title. Feel free to visually customize your plot in any other way that you wish with tick marks, colors, marker styles, and line styles of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_hr_avg_counts = bike[[\"hr\", \"casual\", \"registered\"]].groupby(\"hr\").agg(np.mean).set_index(np.arange(0,24))\n",
    "bike_hr_avg_counts[\"hr\"]=np.arange(1,25)\n",
    "bike_hr_avg_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Remember: One numerical variable on the y-axis and one ordinal variable on the x-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** What does the plot you just made show us? What conclusions can we draw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write description here ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** Also using the `bike_hr_avg_counts` dataframe, plot the average number of casual riders per hour of the day and the average number of registered riders per hour of the day **on the same plot**. Make the `registered` rider plot red and make the `casual` rider plot blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** What does the plot you just made show us? What conclusions can we draw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write description here ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='snslineplots'></a>\n",
    "### Lineplots in Seaborn\n",
    "The function to create [Lineplots in Seaborn](https://seaborn.pydata.org/generated/seaborn.lineplot.html) follow a very similar to its Matplotlib counterpart in terms of its arguments. Like `plt.plot()` in Matplotlib, the arguments of `sns.lineplot()` can be either NumPy arrays or Python lists.\n",
    "\n",
    "    sns.lineplot(x_values, y_values)\n",
    "    \n",
    "**Practice:** Recreate your lineplot of the average number of registered bikeshare riders per hour of the day, this time using Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that's extra cool about using Seaborn is that in some ways it is less verbose than Matplotlib. For example, in Matplotlib we would have to specify our x-values as `bike_hr_avg_counts[\"mnth\"]` and our y-values as `bike_hr_avg_counts[\"cnt\"]`. However, because our list of x-values and our list of y-values come from the same dataframe, Seaborn can make this more concise with the following syntax:\n",
    "\n",
    "    sns.lineplot(data=dataframe_name, x=\"x_values\", y=\"y_values\")\n",
    "    \n",
    "Note that the `data` argument is the name of your dataframe, while `x` and `y` are strings that are the column names of the `x` and `y` variables you want to plot. This code is more readable and concise than the previous syntax because it specifies the dataframe name only once, since repeating the dataframe name in `sns.lineplot(bike_hr_avg_counts[\"hr\"], bike_hr_avg_counts[\"registered\"]`, for example, can be redundant.\n",
    "\n",
    "**Practice:** Recreate your **overlaid** lineplot that includes the plot of both average number of registered riders per hour of the day and casual riders per hour of the day, but this time using this cool new Seaborn syntax! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting lineplots in Seaborn also has some other useful and cool features. For example, the lineplot we've been creating has been from data that has one singular count value per one singular month value. Run the following code to see how Seaborn can plot the a similar lineplot to our previous visualization of the average number of registered riders per hour of the day: here we call upon the original `bike` dataframe, but this time our visualization includes new interesting information about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=bike, x=\"hr\", y=\"registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the lineplot itself is the same, but now there is a lightly shaded region surrounding it. This region represents the spread or variability of the y-values at every x-value point, while the solid line represents the \"middle\" or average y-value per x-value. The larger the light shaded area, the greater spread or variability the y-values have at that particular given x-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='snshue'></a>\n",
    "### `Hue` in Seaborn\n",
    "`sns.lineplot()` also has the optional argument `hue` which is set to a column name in your dataframe that you want to color code; generally you want to color code according to some type of categorical variable.\n",
    "\n",
    "For example, we can color code our plot of average number of registered riders per hour of the day according to the variable `workingday`. We do this by setting `hue=\"workingday\"` within the `sns.lineplot()` function. The result is an overlaid lineplot: one plot represents average number of registered riders per hour of the way on working days (`workingday=1`), and the other represents average number of registered riders per hour of the way on non-working days (`workingday=0`).\n",
    "\n",
    "**Note that the `hue` argument is not limited to only `sns.lineplot()`.** It can be used for many many other Seaborn plots too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=bike, x=\"hr\", y=\"registered\", hue=\"workingday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='barplots'></a>\n",
    "## Bar Plots\n",
    "\n",
    "Barplots show the relationship between a numerical and a categorical variable. Each bar is a different category and the height of each bar is the numerical value.\n",
    "- Matplotlib documentation for [bar plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.bar.html)\n",
    "- Seaborn documentation for [bar plots](https://seaborn.pydata.org/generated/seaborn.barplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "\n",
    "# This groups the bike sharing dataset by the column \"weathersit\" and sums the rest of the columns. \n",
    "# Why do we want to sum instead of just calling count?\n",
    "\n",
    "weather = bike.groupby(\"weathersit\").sum()\n",
    "plt.bar(x = weather.index, height = weather['cnt']);\n",
    "plt.xlabel(\"Weather Condition\")\n",
    "plt.ylabel(\"Bike Rides\")\n",
    "plt.title(\"Total Number of Bike Rides for Each Weather Condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "sns.barplot(x = weather.index , y = 'cnt', data = weather);\n",
    "plt.xlabel(\"Weather Condition\")\n",
    "plt.ylabel(\"Bike Rides\")\n",
    "plt.title(\"Total Number of Bike Rides for Each Weather Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** What does the plot you just made show us? What conclusions can we draw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write description here ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Now try making a barplot in either Matplotlib or Seaborn that shows the total number of bike rides for each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_days = bike.groupby('weekday').sum() #bike.groupby(...)\n",
    "# Your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check-in Question:** Why are we using bar plot? What is the numerical variable and what is the categorical variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scatterplots'></a>\n",
    "## Scatterplots\n",
    "\n",
    "Scatterplots are used to visualize relationships between **two numeric variables**, particularly if both of them are continuous numeric. A scatterplot consists of data points, or *markers*, that are plotted on an *x,y* coordinate plane. Each data point represents a single observation from a dataset and is characterized by two variables, one mapped to the x-axis and the other mapped to the y-axis.\n",
    "\n",
    "However, unlike a lineplot, in a scatterplot there is not only one marker per x coordinate -value, and line segements do not connect each marker. Hence, a scatterplot often resembles **a cloud of data points** that hopefully resemble some discernible trend that can be used to summarize some sort of relationship or correlation between the x-variable and the y-variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pltscatter'></a>\n",
    "### Scatterplots in Matplotlib\n",
    "[Scatterplots in Matplotlib](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html?highlight=scatter#matplotlib.pyplot.scatter) also have a similar function and argument structure as the lineplot function, `plt.plot()`. The function to make a scatterplot in Matplotlib is `plt.scatter()` which takes in the following essential arguments:\n",
    "\n",
    "    plt.scatter(x_values, y_values)\n",
    "    \n",
    "Similar to `plt.plot()`, the `x_values` and `y_values` can be either in the form of NumPy arrays or Python lists.\n",
    "\n",
    "**Practice:** Using the `bike` dataframe, make a Matplotlib scatterplot of the number of casual riders on the x-axis and the number of registered riders on the y-axis. Remember to label your axes and title your plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting plot should generate a lot of questions. There seem to be two clouds of points that seem to both have an upward trend, but in different directions. How can we investigate this further? Luckily, the utilities of Seaborn can help us out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='snsscatter'></a>\n",
    "### Scatterplots in Seaborn\n",
    "Plotting [scatterplots in Seaborn](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) has some extra data visualization advantages that either Matplotlib doesn't have or can't easily accomplish. Take, for example, the `hue` argument. Maybe the divergence we see in the cloud of points in our scatterplot may be due to another variable. Let's see!\n",
    "\n",
    "**Practice:** Recreate your scatterplot from above, but this time use Seaborn and set `hue` equal to `\"workingday\"`. How does this give us more useful information about the relationship between the number of registered riders and the number of casual riders?\n",
    "\n",
    "The function and syntax to create a scatterplot is as follows. Again, you should notice that it is very similar to its Matplotlib counterpart, and the arguments are similar to the other data visualization functions that we have learned so far.\n",
    "\n",
    "    sns.scatterplot(x_values, y_values, hue) \n",
    "    sns.scatterplot(data, x_values, y_values, hue) \n",
    "The first version of `sns.scatterplot()` has `x_values` and `y_values` as either NumPy arrays or Python lists. The second version of `sns.scatterplot()` has `data` set to the name of a dataframe, and `x_values` and `y_values` are set to strings that are the column names of the desired x and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** What does the plot you just made show us? What conclusions can we draw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write description here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='histograms'></a>\n",
    "## Histograms\n",
    "- Histograms are charts that show the distribution of a numerical variable\n",
    "- Histograms use bins (each bar is a bin)\n",
    "- Bins can be of unequal widths \n",
    "- Binning counts the number of numerical values within each bin\n",
    "- The x-axis is the numerical variable that we're observing\n",
    "- The y-axis is a rate (e.g. % per year)\n",
    "- The **area** of each bin (height * width) is the proportion of individuals in the dataset within that bin\n",
    "- The total area of the distribution sums to 1\n",
    "- Matplotlib documentation for [histograms](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html)\n",
    "- Seaborn documentation for [histograms](https://seaborn.pydata.org/generated/seaborn.distplot.html)\n",
    "\n",
    "**Useful resources:** \n",
    "- Data 8 [Slides](https://docs.google.com/presentation/d/1gak73b-xDk2VnQeS-MvEpTrxV1xPP5gy9g0nfiiBx5Q/edit#slide=id.g40eea6abfe_0_95)\n",
    "- Data 8 [Textbook](https://www.inferentialthinking.com/chapters/07/2/Visualizing_Numerical_Distributions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function and syntax to create a histogram is as follows. Again, you should notice that it is very similar to its Matplotlib counterpart, and the arguments are similar to the other data visualization functions that we have learned so far.\n",
    "\n",
    "    plt.hist(x_values, bins = n_bins)\n",
    "    sns.distplot(x_values, bins = bins, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "bins = np.arange(0, 3410 + 350, 350)\n",
    "plt.hist(daily_counts['casual'], bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "sns.distplot(daily_counts['casual'], bins = bins, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(daily_counts['casual'], label='casual', kde = False)\n",
    "sns.distplot(daily_counts['registered'],  label='registered', kde = False, color='green')\n",
    "plt.legend()\n",
    "plt.title(\"Distribution Comparison of Casual vs Registered Riders\")\n",
    "plt.xlabel(\"Rider Count\")\n",
    "plt.ylabel(\"Density\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a histogram showing the distribution of the total rider count.\n",
    "*Hint: Do we need to create a new column for the total rider count?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boxandviolin'></a>\n",
    "## Box Plots \n",
    "- Matplotlib [documentation](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html)\n",
    "- Seaborn [documentation](https://seaborn.pydata.org/generated/seaborn.boxplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(daily_counts[[\"casual\", 'registered']].values, labels = [\"Casual\", \"Registered\"]);\n",
    "plt.ylabel(\"Rider Count\")\n",
    "plt.title(\"Distribution of Casual and Register Rider Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Try making a boxplot below of the distribution of registered riders. Don't forget your labels and titles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic data set\n",
    "<a id='data-loading'></a>\n",
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the test and training data are in the titanic folder and are named \"train.csv\", \"test.csv\" respectively, please fill in the lines below to properly load the titanic dataframes. <br> <br>\n",
    "What is the file type for these data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = ...\n",
    "titanic_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Data Formats** <br> <br>\n",
    "In some cases, data is not stored as a .csv file. Here are some ways to work with other common data formats. <br>\n",
    "<br>**TSV (Tab Separated Value):** Exactly like a .csv, except tabs separate values instead of commas. To read in a .tsv in pandas, use pd.read_csv('filename.csv', sep='\\t')<br>\n",
    "<br>**JSON (JavaScript Object Notation):** Data is stored as a set of nested arrays and dictionaries. An example of when you might work with JSON data is if you use an API (e.x. Yelp, Google, ..) to retrieve information from another website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     column name     |     description     |\n",
    "|-----------|-----------|\n",
    "|PassengerId|Passenger ID|\n",
    "|Survived|0 = no, 1 = yes|\n",
    "|Pclass|Ticket class|\n",
    "|Name|Passenger name|\n",
    "|Sex|Sex|\n",
    "|Age|Age|\n",
    "|SibSp|# of siblings/spouses aboard the Titanic|\n",
    "|Parch|# of parents/children aboard the Titanic|\n",
    "|Ticket|Ticket number|\n",
    "|Fare|Passenger fare|\n",
    "|Cabin|Cabin number|\n",
    "|Embarked|Port of embarkation|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "### Exploratory data analysis\n",
    "**Central question: what factors/variables improve an individual's chance of survival during the Titanic diseaster** <br> <br>\n",
    "Let's start with exploratory data analysis (EDA) or initial investigation on data to discover patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-34ce84e0-3dc7-4b34-a603-fae06ab0f04a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's look at the columns we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-7ccf74c4-74b9-4e43-abd2-8ad7fb52218f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 56,
    "execution_start": 1615595938443,
    "source_hash": "71a6512c"
   },
   "outputs": [],
   "source": [
    "titanic_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-08c0ed7e-5635-41e2-b874-0efd9ddf7c88",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The first column is **PassengerId**, which is just a numbering of the passengers and a **primary key**, or single identifier of a row of the table. It won't help us determine if each passenger survived. What we can do, change our **index** so that we use this field instead. Why? This makes more sense: the index should be able to uniquely define each passenger aboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-6028a013-e5ca-4a0b-a3ed-1c49d933c1c6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1615599041838,
    "source_hash": "ef54151e"
   },
   "outputs": [],
   "source": [
    "titanic_train = titanic_train.set_index('PassengerId')\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-fc84fd27-a5fa-4379-99c0-4941da559b38",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The next column is **Survived**, which is our target variable.  <br>\n",
    "**Check in question:** what do 1 and 0 represent? <br>\n",
    "*answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-81406174-971a-4741-b386-d65e308deede",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1615599051024,
    "source_hash": "fac95a3c"
   },
   "outputs": [],
   "source": [
    "titanic_train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-b0669f00-cf74-4146-8a4f-1c7c5d0acaad",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The next column is called **Pclass**. We're not really sure what that means, so let's investigate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-cc2f4851-fba4-432d-bfe2-39cac8219947",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1615599061097,
    "source_hash": "7865de33"
   },
   "outputs": [],
   "source": [
    "titanic_train['Pclass'].unique() # gets all possible values in this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-9d7d73ee-5a40-47ec-8539-3493894c4c67",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "When you have an historical dataset, you can figure out what columns mean with a little research. [Here](https://www.kaggle.com/c/titanic/data) is a description of all of the columns. The same information is also at the start of this section. **Pclass** is the passenger class (like first-class on a flight).\n",
    "\n",
    "One of the most important columns in the Titanic dataset is the \"Survived\" column, which we use as our labels. In order to get a feel for the distribution, let's take a closer look at the data. The pandas function **value_counts()** is very useful in EDA, since it displays the counts of each unique value in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00030-eaac6b61-6e27-47cc-9aea-78b1e2fdaa05",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1615599072586,
    "source_hash": "140448c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_train['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-a3a98314-8dd5-4e43-9d37-1ec7eb2a719f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This shows us that 549 passengers died and 342 passengers survived. We can take this data and plot this in a barplot by using the `value_counts` function. Here, **index** refers to the 0/1 labels of our data (aka whether the passenger survived or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows of data are included in this data frame? <br> \n",
    "*answer here*\n",
    "<br>What is the granularity of the data set? In other words, what does each row represent? <br>\n",
    "*answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice not all columns are included in the summary dataframe. Why is that? <br>\n",
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bar plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a count table to help with the bar graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_table = titanic_train.groupby(\"Pclass\").agg(\"count\")\n",
    "count_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Looking at this table, how many passengers are in first class? How many passengers survived from first class? (trick question)<br>\n",
    "*answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a bar graph to show how many passengers were in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = count_table.index, height = count_table['Name'])\n",
    "plt.ylabel('count')\n",
    "plt.title('Passenger by Class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a graph to show how many passengers from each class survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=count_table.index,y=count_table['Name']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hue**: Many Seaborn plots have the optional argument hue which is set to a column name in your dataframe that you want to color code; generally you want to color code according to some type of categorical variable. For example, let's say we want to plot the counts of passengers broken down by survival and the their class. We can use the 'countplot' function and set the hue parameter equal to the \"Pclass\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=titanic_train['Survived'],hue = titanic_train['Pclass']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what does this countplot tell you?<br>\n",
    "*answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can age be a factor that influences survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_survived_age = titanic_train[titanic_train['Survived'] == 1]['Age']\n",
    "train_no_survived_age = titanic_train[titanic_train['Survived'] == 0]['Age']\n",
    "\n",
    "sns.distplot(train_survived_age, kde = False, label=\"Survived\", color=\"green\");\n",
    "sns.distplot(train_no_survived_age, kde= False, label=\"Didn't survive\", color=\"red\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** create your own graph to answer one of the following questions: (or create your own question) <br>\n",
    "Does passenger's sex make a difference in their chance of survival? <br>\n",
    "What is the relationship between number of siblings or spouses on board (SibSp) and survival? <br>\n",
    "How about number of children or parents on board (Parch) and suvival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*explanation for your graph*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00064-80e37455-f6b9-4b15-8884-211bf4ca9ab5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We can look at the **Cabin** column next. This is also tough to analyze alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00065-12e5cf31-d287-439f-a073-40fe65319336",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1615595944157,
    "source_hash": "b8d4f329"
   },
   "outputs": [],
   "source": [
    "titanic_train['Cabin'].head() # what does NaN mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00066-721f065e-f021-40b8-a830-fcff0eb9482b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's look at the first 5 non-null values instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00067-f7f762ce-476c-4efc-86aa-efa0ee25f7c3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1615595944165,
    "source_hash": "7f4109c3"
   },
   "outputs": [],
   "source": [
    "titanic_train['Cabin'][~pd.isnull(titanic_train['Cabin'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00068-8835963a-9c32-4e94-bc99-c969e70948c9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "There is probably significance in the letter that precedes the number (maybe the deck of the ship that the cabin is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00069-986b4c76-cf81-4cf3-be89-124cb42e9d37",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1615595944213,
    "source_hash": "66384d90"
   },
   "outputs": [],
   "source": [
    "decks = titanic_train['Cabin'].apply(lambda s: s[0] if s is not np.nan else 'NO-DECK')\n",
    "# we want to also capture those who didn't have a cabin in our column, so we assign it to a value as well\n",
    "decks.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00070-9a809f4d-3455-4778-b6b5-dc8cb7603e75",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Here's a picture of the Titanic ship.\n",
    "\n",
    "<img src='titanic.png' style='width: 300px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00071-ba5e4812-ebd0-4064-9ce4-4f7495da9172",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "There isn't a \"T\" deck, so that was probably an error. Let's leave this out of our graph (this will be important later in the model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00072-03bcc78b-affc-4c78-b159-35bff80ba2e1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 356,
    "execution_start": 1615595944214,
    "source_hash": "ebff8e85"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=titanic_train['Survived'], hue=decks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00073-a1412e56-028d-4f94-b3b8-f8728d5b1cbb",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We can see that those without a cabin survived at a much lower rate than other cabins, but we can't really see the other decks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00074-fefdfe48-1807-436b-a771-a6482617bb25",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 365,
    "execution_start": 1615595944556,
    "source_hash": "c9b2d338"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=titanic_train['Survived'][decks != 'NO-DECK'], hue=decks[decks != 'NO-DECK']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00078-8aec1986-ea0e-4f4d-a0d8-0b072c2ba5c2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Exploratory data analysis** is one of the most important parts of the data science process. What we've shown above should only be subset of the analysis that is actually done. Understanding the context of the data and features of the data is exceedingly more important that figuring out the best \"model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00079-af5e1e57-2515-4f2d-893f-b16a35f84bb8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<span id=\"feature-engineering\"></span>\n",
    "## Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00080-37ca94ac-88ea-4880-a362-5a19e43ccf7f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The goal of feature engineering is to take your dataset and turn it into a set of **numerical features** for a model to be trained and evaluated on. \n",
    "\n",
    "An important part of **feature engineering** is **data cleaning**, where in creating the features for the model, we make sure that we make sure we have no null values in our final DataFrame, and don't train our model on unusual points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00083-267dbe34-19a0-4b5c-b0af-fb8abb3b3bae",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Removing Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00084-87e617f1-eb22-46d8-8cc9-1b86abdbe344",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's see where the `NaN`s are. We can count how many `NaN`s are in each column using the `pd.isnull()` and `sum()` functions. We're basically converting every value in the dataframe to `True` and `False` values based on whether they are `NaN`, and summing across columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00085-801a186a-c351-43e5-bceb-bcacc0d4f974",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1615595945245,
    "scrolled": false,
    "source_hash": "d1c6971a"
   },
   "outputs": [],
   "source": [
    "pd.isnull(titanic_train).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00086-dad6abc4-4b90-436d-a69d-c7a65a6dcd0b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Dang! `Cabin` has a lot of missing values. There are only 891 values in the `titanic_train` dataframe, and a majority of them are missing. With missing values we have a couple options. The first is *dropping features*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00087-9e9bfbc0-2c23-4ee7-8eec-282d1bebd1e6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Option 1: Dropping Features\n",
    "\n",
    "We might think \"hey, if most of the values don't have a value for `cabin`, we should probably just get rid of this column\". If we want to do that, we could just drop a column in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00088-a1e05ea9-e200-4264-b8c0-05940220ba0d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1615595945273,
    "source_hash": "c8e7c870"
   },
   "outputs": [],
   "source": [
    "titanic_dropped_col = titanic_train.drop('Cabin', axis=1)\n",
    "titanic_dropped_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00089-64030d1b-5bc7-407d-8ad7-ee29e92cbd14",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Easy! However, what if we lost some valuable information by dropping that column? We'll go into more Exploratory Data Analysis (EDA) later, but there are some small exploratory steps we can take to inform our data cleaning. For example, just for fun, let's take a look at the survival rates between passengers that had a value for `Cabin` and passengers that did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00090-6f33cb7b-3b15-4d68-a0b2-da8fc148763b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1615595945302,
    "source_hash": "615214af"
   },
   "outputs": [],
   "source": [
    "titanic_train['Survived'][~titanic_train['Cabin'].isna()].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00091-fa7e1a61-180e-43c3-95d4-0b9e7f736257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1615595945303,
    "source_hash": "ba3efbc"
   },
   "outputs": [],
   "source": [
    "titanic_train['Survived'][titanic_train['Cabin'].isna()].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00092-c22733aa-d263-4448-ad14-df8465cb7f89",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Wow, that is a non-trivial difference! This is an example of when `NaN` can provide information instead of just being extraneous information. For now, let's keep the `Cabin` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00093-4511e075-b81f-4b3b-8263-1e95b4de3fb4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Option 2: Drop Rows\n",
    "\n",
    "Another column with a good number of missing values is `Age`, with `177` of `891` being missing. We *could* drop the column, but our knowledge of history might remind us that \"women and children\" were prioritized, so age could provide valuable information. Alternatively, we can drop rows with missing values for features we think are important. We can do this in a very similar way to dropping columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00094-9d92a0a1-af8e-4a41-92d4-b43d55300f91",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1615595945304,
    "source_hash": "4925300f"
   },
   "outputs": [],
   "source": [
    "titanic_dropped_rows = titanic_train.dropna(axis=0, subset=['Age'])\n",
    "print(titanic_dropped_rows.isna().sum())\n",
    "print(titanic_dropped_rows.shape, titanic_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00095-eee304be-f32a-4c20-b88d-b8b80052bd0a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now we don't have any `NaN` values in `Age` and we kept all of the original features, but we have fewer rows than we did before! We're missing out on the other features of the rows that we removed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00096-737ec361-2bfa-4b0b-b8d6-986db7ae77b9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Option 3: Impute Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00097-5aa077c1-d331-4296-b1fa-2f61af695826",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "It's always better to have more data to train on, so we are losing some information by dropping columns. How can we keep all of the observations in our training data while also getting rid of `NaN`s? We can try to *impute* or guess what the values should be based on the present values. How you impute depends on your data. \n",
    "\n",
    "For example, for `Age`, we might want to fill in the `NaN` values with the average age. We can do this using the `fillna()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00098-9b104cd8-2946-414d-8bc4-41b76a359d7e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1615595945418,
    "source_hash": "6fdc8f3f"
   },
   "outputs": [],
   "source": [
    "titanic_train['Age'] = titanic_train['Age'].fillna(titanic_train['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00099-8868f56b-3eb9-40bd-836c-94045ac4ced1",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We've managed to remove the `NaN` values, without reducing the number of observations in our training set! However, clearly this method won't work on `Cabin` and `Embarked`, because these are categorical variables with no concept of average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00113-cd0118bc-b37b-4d58-8b6b-d7394bc8416d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### One-Hot Encoding\n",
    "We cleaned the categorical variables earlier, but they're still non-numeric, and for our models, we need to make all of our data numeric. To convert categorical variables to numeric values, we can use a method called *one-hot encoding*. Basically, we will make a new column for each category and set a flag of 1 or 0 – 1 if that observation is in that category, and 0 if it's not.\n",
    "\n",
    "We basically want to achieve something that looks like this:\n",
    "\n",
    "<img src='one_hot_1.png' style='width: 500px'></img>\n",
    "\n",
    "How do we do that? Luckily, pandas has a built-in function called `get_dummies()` that will do the one-hot encoding for us! *One-hot encoding is also called dummy encoding*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note:** when we use dummy variables for regression model, we usually drop one dummy column to avoid perfect collinearity. Don't worry about the regression model now, but just a note for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00114-37ca6851-4722-4ff3-a6f6-1413bd4b1193",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1615595945858,
    "scrolled": false,
    "source_hash": "2ed68322"
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(titanic_train, columns=['Embarked']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00115-ad637fb9-4b67-465b-a3fd-73d13ce4ef45",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We can also do this for `Sex` and `Cabin`. We could do it separately, but the columns argument takes in a list of column names, so we can do this all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00116-2646faf8-fa27-4340-bae6-606fd2d17e96",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 263,
    "execution_start": 1615595945864,
    "scrolled": false,
    "source_hash": "934e3228"
   },
   "outputs": [],
   "source": [
    "titanic_train = pd.get_dummies(titanic_train, columns=['Embarked', 'Sex', 'Cabin'])\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00125-5cb93ffb-1278-4264-93e0-7dbc205080e0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "What are some potential problems that one-hot encoding will create?\n",
    "(Hint: Think about about extreme cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00128-42bf9492-cc8b-4924-9707-e89c2fb89b1f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Let's say in one column, we have 10000 unique categorical values. When we use one-hot encoding on that column, we would be creating 10000 more columns, most of them will be very sparse(i.e. a lot of zeros in the column). This will be an inefficient way to preprocess the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00136-e80a83e5-9a52-4600-a2de-829a9b8e48dd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<pre> \n",
    "Brainstorm: Here's a list of unique values occured in one particular categorical column: \n",
    "<br /> Categorical Value | Occurance\n",
    "<br />              A        1000\n",
    "<br />              B        800\n",
    "<br />              C        580\n",
    "<br />              D        15\n",
    "<br />              E        10\n",
    "<br />              F        9\n",
    "<br />              G        8\n",
    "<br />              H        7\n",
    "<br />              I        6\n",
    "<br />              J        5\n",
    "<br />              K        4\n",
    "<br />              L        3\n",
    "<br />              M        2\n",
    "<br />              N        1\n",
    "How can you efficiently handle this column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00136-8f3b5487-d158-4da4-adee-6d7e61c3a12b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "One idea would be to create a rare instance class and put all rare values into that class:\n",
    "<pre> \n",
    "<br /> Categorical Value | Occurance\n",
    "<br />              A        1000\n",
    "<br />              B        800\n",
    "<br />              C        580\n",
    "<br />             rare      15+10+9+...+1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00138-96c2a1f7-6ac7-4e65-84f6-4ef57d6a55f0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now you have only 4 categorical values instead of 14. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Practice one hot encoding on the bike data set. Start with identifying the variables that would require one hot encoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes our data is not linear, and we can perform transformations so the data will fit the linear model.\n",
    "<img src='transformations.png' style='width: 400px'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.arange(50)\n",
    "y_1 = np.log(x_1)\n",
    "plt.scatter(x_1,y_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_log = np.log(x_1)\n",
    "plt.scatter(x_1_log,y_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## Resources\n",
    "* [Data100 Fall 2019: Visualization I, Visualization II, Homework 3; by Professors Josh Hug and Deborah Nolan](http://www.ds100.org/fa19/syllabus/)\n",
    "- [A Datascience Workflow - Towards Data Science](https://towardsdatascience.com/a-data-science-workflow-26c3f05a010e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
