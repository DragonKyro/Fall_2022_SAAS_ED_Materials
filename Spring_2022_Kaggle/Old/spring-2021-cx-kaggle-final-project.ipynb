{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022627,
     "end_time": "2021-04-23T17:00:57.110693",
     "exception": false,
     "start_time": "2021-04-23T17:00:57.088066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Career Exploration Kaggle Competition: Rain in Australia Prediction\n",
    "\n",
    "### Hosted by and maintained by the [Students Association of Applied Statistics (SAAS)](https://saas.berkeley.edu).  Authored by Derek Cai(dcai@berkeley.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020511,
     "end_time": "2021-04-23T17:00:57.152031",
     "exception": false,
     "start_time": "2021-04-23T17:00:57.131520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:57.200913Z",
     "iopub.status.busy": "2021-04-23T17:00:57.200199Z",
     "iopub.status.idle": "2021-04-23T17:00:57.203567Z",
     "shell.execute_reply": "2021-04-23T17:00:57.202876Z"
    },
    "papermill": {
     "duration": 0.030691,
     "end_time": "2021-04-23T17:00:57.203805",
     "exception": false,
     "start_time": "2021-04-23T17:00:57.173114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020415,
     "end_time": "2021-04-23T17:00:57.245408",
     "exception": false,
     "start_time": "2021-04-23T17:00:57.224993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:57.292045Z",
     "iopub.status.busy": "2021-04-23T17:00:57.291350Z",
     "iopub.status.idle": "2021-04-23T17:00:58.229110Z",
     "shell.execute_reply": "2021-04-23T17:00:58.228388Z"
    },
    "papermill": {
     "duration": 0.962691,
     "end_time": "2021-04-23T17:00:58.229259",
     "exception": false,
     "start_time": "2021-04-23T17:00:57.266568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../input/saas-2021-spring-cx-kaggle-compeition/train_features.csv\")\n",
    "X_test = pd.read_csv(\"../input/saas-2021-spring-cx-kaggle-compeition/test_features.csv\")\n",
    "y_train = pd.read_csv(\"../input/saas-2021-spring-cx-kaggle-compeition/train_targets.csv\")\n",
    "del y_train['Id']\n",
    "sample_submission = pd.read_csv(\"../input/saas-2021-spring-cx-kaggle-compeition/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020749,
     "end_time": "2021-04-23T17:00:58.271348",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.250599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020641,
     "end_time": "2021-04-23T17:00:58.313145",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.292504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In our Visualization + Data Cleaning HW, you have explored and got familiar the dataset. Now is the time to do some feature engineering! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.360887Z",
     "iopub.status.busy": "2021-04-23T17:00:58.360142Z",
     "iopub.status.idle": "2021-04-23T17:00:58.432628Z",
     "shell.execute_reply": "2021-04-23T17:00:58.431934Z"
    },
    "papermill": {
     "duration": 0.09851,
     "end_time": "2021-04-23T17:00:58.432776",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.334266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#as mentioned in lecture, when doing feature engineering, it's better to merge train and test datasets first and do operations on the entire merged dataset\n",
    "full_data = pd.concat([X_train, X_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.478904Z",
     "iopub.status.busy": "2021-04-23T17:00:58.478228Z",
     "iopub.status.idle": "2021-04-23T17:00:58.483164Z",
     "shell.execute_reply": "2021-04-23T17:00:58.482601Z"
    },
    "papermill": {
     "duration": 0.029246,
     "end_time": "2021-04-23T17:00:58.483311",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.454065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checking if the merged dataset has the correct number of rows\n",
    "assert full_data.shape[0] == X_train.shape[0]+X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.536147Z",
     "iopub.status.busy": "2021-04-23T17:00:58.535214Z",
     "iopub.status.idle": "2021-04-23T17:00:58.539314Z",
     "shell.execute_reply": "2021-04-23T17:00:58.539836Z"
    },
    "papermill": {
     "duration": 0.034142,
     "end_time": "2021-04-23T17:00:58.540008",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.505866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
       "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
       "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
       "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
       "       'Temp3pm', 'RainToday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021895,
     "end_time": "2021-04-23T17:00:58.583952",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.562057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The above shows all the column names of the training dataset. Do you think all columns are useful in doing rain prediction? For instance, is knowing the date really going to help us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02134,
     "end_time": "2021-04-23T17:00:58.627024",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.605684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dropping Features\n",
    "Not all features are useful. Drop some features of full_data if you want!\n",
    "Resource: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.675553Z",
     "iopub.status.busy": "2021-04-23T17:00:58.674582Z",
     "iopub.status.idle": "2021-04-23T17:00:58.679287Z",
     "shell.execute_reply": "2021-04-23T17:00:58.678781Z"
    },
    "papermill": {
     "duration": 0.030477,
     "end_time": "2021-04-23T17:00:58.679428",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.648951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.729081Z",
     "iopub.status.busy": "2021-04-23T17:00:58.728213Z",
     "iopub.status.idle": "2021-04-23T17:00:58.734292Z",
     "shell.execute_reply": "2021-04-23T17:00:58.733529Z"
    },
    "papermill": {
     "duration": 0.032521,
     "end_time": "2021-04-23T17:00:58.734441",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.701920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original full_data has 22 columns, after you drop some columns, the below expression will return a number less than 23\n",
    "len(full_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022435,
     "end_time": "2021-04-23T17:00:58.779573",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.757138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fill in the Missing Values\n",
    "In Visualization + Data Cleaning HW, we have explored techniques of dealing with missing values. Perform the same techniques on all columns of full_data that contain missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.859106Z",
     "iopub.status.busy": "2021-04-23T17:00:58.858157Z",
     "iopub.status.idle": "2021-04-23T17:00:58.928928Z",
     "shell.execute_reply": "2021-04-23T17:00:58.928248Z"
    },
    "papermill": {
     "duration": 0.127081,
     "end_time": "2021-04-23T17:00:58.929073",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.801992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp            637\n",
       "MaxTemp            322\n",
       "Rainfall          1406\n",
       "Evaporation      60843\n",
       "Sunshine         67816\n",
       "WindGustDir       9330\n",
       "WindGustSpeed     9270\n",
       "WindDir9am       10013\n",
       "WindDir3pm        3778\n",
       "WindSpeed9am      1348\n",
       "WindSpeed3pm      2630\n",
       "Humidity9am       1774\n",
       "Humidity3pm       3610\n",
       "Pressure9am      14014\n",
       "Pressure3pm      13981\n",
       "Cloud9am         53657\n",
       "Cloud3pm         57094\n",
       "Temp9am            904\n",
       "Temp3pm           2726\n",
       "RainToday         1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below expression shows the number of missing values in each column\n",
    "full_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:58.979952Z",
     "iopub.status.busy": "2021-04-23T17:00:58.979322Z",
     "iopub.status.idle": "2021-04-23T17:00:58.981767Z",
     "shell.execute_reply": "2021-04-23T17:00:58.982255Z"
    },
    "papermill": {
     "duration": 0.029706,
     "end_time": "2021-04-23T17:00:58.982421",
     "exception": false,
     "start_time": "2021-04-23T17:00:58.952715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022502,
     "end_time": "2021-04-23T17:00:59.028067",
     "exception": false,
     "start_time": "2021-04-23T17:00:59.005565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### One Hot Encoding\n",
    "One-hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:59.077865Z",
     "iopub.status.busy": "2021-04-23T17:00:59.077203Z",
     "iopub.status.idle": "2021-04-23T17:00:59.080328Z",
     "shell.execute_reply": "2021-04-23T17:00:59.080822Z"
    },
    "papermill": {
     "duration": 0.029856,
     "end_time": "2021-04-23T17:00:59.081004",
     "exception": false,
     "start_time": "2021-04-23T17:00:59.051148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022991,
     "end_time": "2021-04-23T17:00:59.127378",
     "exception": false,
     "start_time": "2021-04-23T17:00:59.104387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Optional: Dimensionality Reduction\n",
    "When the data has high dimensions(a lot of columns), it is very useful to use PCA to lower the dimension of the data during feature engineering. \n",
    "Since we only have around 20 features, this is not necessary. But it could potentially help with your kaggle score.\n",
    "PS: PCA is designed for continuous variables, so maybe you should try ignore categorical columns for PCA.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:00:59.178058Z",
     "iopub.status.busy": "2021-04-23T17:00:59.177375Z",
     "iopub.status.idle": "2021-04-23T17:01:00.474837Z",
     "shell.execute_reply": "2021-04-23T17:01:00.474218Z"
    },
    "papermill": {
     "duration": 1.323798,
     "end_time": "2021-04-23T17:01:00.474999",
     "exception": false,
     "start_time": "2021-04-23T17:00:59.151201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optional\n",
    "from sklearn.decomposition import PCA\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025195,
     "end_time": "2021-04-23T17:01:00.525246",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.500051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feel Free to do more feature engineering on df! All the methods listed above are ones to help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:00.584342Z",
     "iopub.status.busy": "2021-04-23T17:01:00.583680Z",
     "iopub.status.idle": "2021-04-23T17:01:00.585926Z",
     "shell.execute_reply": "2021-04-23T17:01:00.586395Z"
    },
    "papermill": {
     "duration": 0.035391,
     "end_time": "2021-04-23T17:01:00.586578",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.551187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting up our engineered df back into training and test\n",
    "X_train = full_data[:X_train.shape[0]]\n",
    "X_test = full_data[X_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:00.640796Z",
     "iopub.status.busy": "2021-04-23T17:01:00.640094Z",
     "iopub.status.idle": "2021-04-23T17:01:00.644901Z",
     "shell.execute_reply": "2021-04-23T17:01:00.645379Z"
    },
    "papermill": {
     "duration": 0.034606,
     "end_time": "2021-04-23T17:01:00.645564",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.610958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117069, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:00.699146Z",
     "iopub.status.busy": "2021-04-23T17:01:00.698414Z",
     "iopub.status.idle": "2021-04-23T17:01:00.704926Z",
     "shell.execute_reply": "2021-04-23T17:01:00.704242Z"
    },
    "papermill": {
     "duration": 0.033828,
     "end_time": "2021-04-23T17:01:00.705072",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.671244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25124, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024793,
     "end_time": "2021-04-23T17:01:00.755322",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.730529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Baseline Model\n",
    "Congrats! You have feature engineered the train and test dataset such that they can be used to build models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024188,
     "end_time": "2021-04-23T17:01:00.804200",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.780012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our Kaggle competition uses MAE(Mean Absolute Error) as our metric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:00.859344Z",
     "iopub.status.busy": "2021-04-23T17:01:00.858391Z",
     "iopub.status.idle": "2021-04-23T17:01:00.861786Z",
     "shell.execute_reply": "2021-04-23T17:01:00.861168Z"
    },
    "papermill": {
     "duration": 0.033338,
     "end_time": "2021-04-23T17:01:00.861935",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.828597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def evaluate(y_pred, y_true):\n",
    "    \"\"\"Returns the MAE(y_pred, y_true)\"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:00.914575Z",
     "iopub.status.busy": "2021-04-23T17:01:00.913895Z",
     "iopub.status.idle": "2021-04-23T17:01:01.370022Z",
     "shell.execute_reply": "2021-04-23T17:01:01.369329Z"
    },
    "papermill": {
     "duration": 0.48365,
     "end_time": "2021-04-23T17:01:01.370166",
     "exception": false,
     "start_time": "2021-04-23T17:01:00.886516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2008-12-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b0f72c968801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the model using our train_features and train_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Use the trained model to predict y_train!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[1;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 305\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2008-12-01'"
     ]
    }
   ],
   "source": [
    "# Build a simple random forest model here\n",
    "# Don't worry if you don't how a random forest works. We will cover that in lecture. \n",
    "# The below code serves as a demonstration of how you generally create a model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate a model \n",
    "clf = RandomForestClassifier(max_depth=1, random_state=0, verbose=1)\n",
    "# Train the model using our train_features and train_targets\n",
    "clf.fit(X_train.to_numpy(), np.ravel(y_train.to_numpy()))\n",
    "# Use the trained model to predict y_train!\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025585,
     "end_time": "2021-04-23T17:01:01.421097",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.395512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross Validation\n",
    "![cross-validation-graphic](https://i.stack.imgur.com/1fXzJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026346,
     "end_time": "2021-04-23T17:01:01.472880",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.446534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Task 1:\n",
    "In Lecture, we have discussed the cross-validtion scheme. Set up your cross validation below. Perform a 5-fold cross-validation on the rain dataset below. You should use 20% of your training data as your validation data. Print out the accuracy of each of your 5 experiment! Feel free to keep the random forest model or use any models of your choosing. DM the screenshot of your code and the printed out 5 experiment accuracy to Derek! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024997,
     "end_time": "2021-04-23T17:01:01.523940",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.498943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Task2: For people scoring above 0.17 on the leaderboard, beat the score 0.17! For people scoring below 0.17, beat your current score! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024836,
     "end_time": "2021-04-23T17:01:01.573990",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.549154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024893,
     "end_time": "2021-04-23T17:01:01.623961",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.599068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create another model that scores decently well and create an ensemble of these 2 models. You can simply average the output predictions of these 2 models or take a weighted average of the output predictions of of these 2 models. Screenshot the code of your second model as well as the final ensemble process to Derek. Your submission should generally be better than your single submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025378,
     "end_time": "2021-04-23T17:01:01.675512",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.650134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026188,
     "end_time": "2021-04-23T17:01:01.727174",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.700986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024804,
     "end_time": "2021-04-23T17:01:01.777836",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.753032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:01.844091Z",
     "iopub.status.busy": "2021-04-23T17:01:01.843114Z",
     "iopub.status.idle": "2021-04-23T17:01:01.848364Z",
     "shell.execute_reply": "2021-04-23T17:01:01.847803Z"
    },
    "papermill": {
     "duration": 0.045535,
     "end_time": "2021-04-23T17:01:01.848509",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.802974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-00d7d9b27790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m25124\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "assert predictions.shape[0] == 25124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:01.916166Z",
     "iopub.status.busy": "2021-04-23T17:01:01.915310Z",
     "iopub.status.idle": "2021-04-23T17:01:01.920339Z",
     "shell.execute_reply": "2021-04-23T17:01:01.919822Z"
    },
    "papermill": {
     "duration": 0.046058,
     "end_time": "2021-04-23T17:01:01.920490",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.874432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9a4fbd0eeb91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RainTomorrow'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "sample_submission['RainTomorrow'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:01.979848Z",
     "iopub.status.busy": "2021-04-23T17:01:01.979138Z",
     "iopub.status.idle": "2021-04-23T17:01:02.031226Z",
     "shell.execute_reply": "2021-04-23T17:01:02.031821Z"
    },
    "papermill": {
     "duration": 0.084748,
     "end_time": "2021-04-23T17:01:02.032135",
     "exception": false,
     "start_time": "2021-04-23T17:01:01.947387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026112,
     "end_time": "2021-04-23T17:01:02.085698",
     "exception": false,
     "start_time": "2021-04-23T17:01:02.059586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Note: submission.csv can be found within the /kaggle/working file on the right side of your screen. Download the csv file and use it for submission!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.806427,
   "end_time": "2021-04-23T17:01:02.824262",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-23T17:00:51.017835",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
